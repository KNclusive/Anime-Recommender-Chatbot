{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ed0145e-207c-471d-9df5-bb81b34b8a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google.oauth2 import service_account\n",
    "from threading import Thread, get_ident\n",
    "import joblib\n",
    "import torch\n",
    "import os\n",
    "import io\n",
    "import csv\n",
    "import random\n",
    "import string\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35da9413",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from recommend import collaborative_main, content_main, popular_main\n",
    "from response import intent_detection, response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cff4b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60971c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_profile_name(existing_names):\n",
    "    # Generate a random length for the profile name (up to 24 characters)\n",
    "    name_length = random.randint(5, min(8, len(string.ascii_letters)))\n",
    "    # Generate a random profile name\n",
    "    profile_name = ''.join(random.choices(string.ascii_letters, k=name_length))\n",
    "    # Ensure the generated name is unique\n",
    "    while profile_name in existing_names:\n",
    "        profile_name = ''.join(random.choices(string.ascii_letters, k=name_length))\n",
    "    return profile_name\n",
    "\n",
    "def add_update_record(csv_file, anime_uid, score = '', profile = '', scores = '', link = ''):\n",
    "    fieldnames = ['uid', 'profile', 'anime_uid', 'score', 'scores', 'link']\n",
    "    # Create a temporary list to hold all records\n",
    "    records = []\n",
    "    max_uid = 0\n",
    "    existing_profile_name = []\n",
    "    is_new_record = True\n",
    "    # Read existing records, update if necessary\n",
    "    with open(csv_file, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            if row['profile'] == profile and row['anime_uid'] == anime_uid:\n",
    "                if score != '': \n",
    "                    row['score'] = score\n",
    "                if scores != '': \n",
    "                    row['scores'] = scores\n",
    "                if link != '':\n",
    "                    row['link'] = link\n",
    "                is_new_record = False\n",
    "            existing_profile_name.append(row['profile'])\n",
    "            if int(row['uid']) > max_uid:\n",
    "                max_uid = int(row['uid'])\n",
    "            records.append(row)\n",
    "    # If it's a new record, add it with a new uid\n",
    "    if is_new_record:\n",
    "        new_uid = max_uid + 1\n",
    "        if profile == '':\n",
    "            profile = generate_profile_name(existing_profile_name)\n",
    "        new_record = {'uid': new_uid, 'profile': profile, 'anime_uid': anime_uid, 'score': score, 'scores': scores, 'link': link}\n",
    "        records.append(new_record)\n",
    "    # Write all records back to the CSV file\n",
    "    with open(csv_file, 'w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "235a9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Google_drive_data_load():\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "    SERVICE_ACCOUNT_FILE = 'Google_Drive_Credentials.json'\n",
    "    global_data['PARENT_FOLDER_ID'] = 'YOUR_DRIVE_FOLDER_ID'\n",
    "    global_data['creds'] = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE,scopes=SCOPES)\n",
    "\n",
    "def load_ChatModel(): # Load DialogPT model\n",
    "    global_data['tokenizer'] = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\", padding_side='left')\n",
    "    global_data['model'] = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "    print(\"Model Load Complete\")\n",
    "\n",
    "def load_model_from_memory(file_id, service, name):\n",
    "    unique_name = f\"{name}_{get_ident()}\"\n",
    "    #Get file from Google Drive\n",
    "    request = service.files().get_media(fileId=file_id)\n",
    "    file_stream = io.FileIO(unique_name, 'w+')\n",
    "    with file_stream:\n",
    "        #Download file to stream\n",
    "        downloader = MediaIoBaseDownload(file_stream, request)\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "        try:\n",
    "            global_data[f'{name}'] = joblib.load(file_stream)\n",
    "            print(f'{name} loaded')\n",
    "        except Exception as e:\n",
    "            print(e, 'a')\n",
    "\n",
    "def list_and_load_models():\n",
    "    init_service = build('drive', 'v3', credentials=global_data.get('creds', None))\n",
    "\n",
    "    # Update the query to search for files in the specified folder\n",
    "    query = f\"'{global_data.get('PARENT_FOLDER_ID', None)}' in parents and trashed=false and mimeType='application/octet-stream'\"\n",
    "    results = init_service.files().list(q=query).execute()\n",
    "\n",
    "    items = results.get('files', [])\n",
    "\n",
    "    if not items:\n",
    "        print('No files found.')\n",
    "    else:\n",
    "        for item in items:\n",
    "            service = build('drive', 'v3', credentials=global_data.get('creds', None))\n",
    "            thread = Thread(target=load_model_from_memory, args=(item['id'], service, item['name']))\n",
    "            thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a958cf1e-6468-46c2-b4c7-c23988171be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    threadstoExecute = [Thread(target=load_ChatModel), Thread(target=list_and_load_models, daemon=True)]\n",
    "    for thread in threadstoExecute: thread.start()\n",
    "    return render_template('chat.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4345f03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_chatting(step, **kwargs):\n",
    "    if step==0:\n",
    "        chat_output = 'Hello, My name is Animebot Nice to Meet you. Provide me your user_id?'\n",
    "        return chat_output, 1\n",
    "    if step==1:\n",
    "        user_id=kwargs.get('message', None)\n",
    "        while 'user_data.joblib' not in global_data:\n",
    "            time.sleep(1)\n",
    "        if user_id in global_data['user_data.joblib']['profile'].values:\n",
    "            chat_output = f\"Hi {user_id}! What kind of anime are you interested in, or is there a specific type of recommendation you're looking for today?\"\n",
    "            return True, chat_output, 2, user_id\n",
    "        else:\n",
    "            user_id=generate_profile_name(global_data['user_data.joblib']['profile'].values)\n",
    "            chat_output = f\"Hi! I have created a new User Id for you, Your User Id is: '{user_id}'. What kind of anime are you interested in, or is there a specific type of recommendation you're looking for today?\"\n",
    "            return False, chat_output, 2, user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15dfd220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memoizing_Chat():\n",
    "    step=0\n",
    "    is_user=False\n",
    "    user_id = ''\n",
    "    def memoized_Chat():\n",
    "        msg = request.form[\"msg\"]\n",
    "        user_input = msg\n",
    "\n",
    "\n",
    "        nonlocal step, is_user, user_id\n",
    "        \n",
    "\n",
    "        # Testing Code Begin\n",
    "        is_recommend = False\n",
    "        is_content = False\n",
    "        \n",
    "        if step==0:\n",
    "            chat_output, step=initial_chatting(step, message=msg)\n",
    "            return chat_output\n",
    "        if step==1:\n",
    "            is_user, chat_output, step, user_id = initial_chatting(step, message=msg)\n",
    "            return chat_output\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            word_list= [\"recommend\", \"advice\", \"give\", \"provide\", \"suggest\", \"intrest\", \"advice\"]\n",
    "\n",
    "            for word in word_list:\n",
    "                if word in user_input.lower():\n",
    "                    is_recommend = True\n",
    "            \n",
    "            if is_recommend:  # Checking if the input is asking for a recommendation\n",
    "\n",
    "                anime_features = intent_detection(user_input)\n",
    "\n",
    "                if anime_features: is_content=True\n",
    "                \n",
    "                if is_content: # Checking if the input has a feature list\n",
    "                    \n",
    "                    # Waiting for the relevant files to be loaded\n",
    "                    while 'knn_model_Content.joblib' not in global_data:\n",
    "                        time.sleep(1)\n",
    "                    while 'Combined_Embedding.joblib' not in global_data:\n",
    "                        time.sleep(1)\n",
    "                    while 'anime_data.joblib' not in global_data:\n",
    "                        time.sleep(1)\n",
    "                    \n",
    "                    lom, found = content_main(anime_features, \n",
    "                                  global_data['knn_model_Content.joblib'],\n",
    "                                  global_data['Combined_Embedding.joblib'],\n",
    "                                  global_data['anime_data.joblib'])\n",
    "                \n",
    "                elif is_user: # Checking if it is an exising user\n",
    "                    \n",
    "                    # Waiting for the relevant files to be loaded\n",
    "                    while 'knn_model_Collaborative.joblib' not in global_data:\n",
    "                        time.sleep(1)\n",
    "                    while 'profile_to_index.joblib' not in global_data:\n",
    "                        time.sleep(1)\n",
    "                    while 'index_to_profile.joblib' not in global_data:\n",
    "                        time.sleep(1)\n",
    "                    while 'user_item_matrix.joblib' not in global_data:\n",
    "                        time.sleep(1)\n",
    "                    while 'user_data.joblib' not in global_data:\n",
    "                        time.sleep(1)\n",
    "                    while 'rating_data.joblib' not in global_data:\n",
    "                        time.sleep(1)\n",
    "                    while 'anime_data.joblib' not in global_data:\n",
    "                        time.sleep(1)\n",
    "                        \n",
    "                    lom, found = collaborative_main(user_id, global_data['knn_model_Collaborative.joblib'], \n",
    "                                global_data['profile_to_index.joblib'], \n",
    "                                global_data['index_to_profile.joblib'], \n",
    "                                global_data['user_item_matrix.joblib'], \n",
    "                                global_data['user_data.joblib'], \n",
    "                                global_data['rating_data.joblib'], \n",
    "                                global_data['anime_data.joblib'], 5)\n",
    "                \n",
    "                else: # Recommending the most popular movies if it is a new user without any specific request\n",
    "                    \n",
    "                    while 'anime_data.joblib' not in global_data:\n",
    "                        time.sleep(1)\n",
    "                    \n",
    "                    lom, found = popular_main(global_data['anime_data.joblib'])\n",
    "                    \n",
    "                chat_output = response_text(user_input, lom, found)\n",
    "                \n",
    "                return chat_output\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                return get_Chat_response(user_input, global_data.get('model', None), global_data.get('tokenizer', None))\n",
    "            \n",
    "    return memoized_Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09afedd5-f078-483c-94ba-2160499aa939",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/get\", methods=[\"GET\", \"POST\"])\n",
    "def call_Chat():\n",
    "    return Chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be9ae4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Chat_response(user_input, model, tokenizer):\n",
    "    text = user_input\n",
    "    encoded_user_input = tokenizer.encode(str(text) + tokenizer.eos_token, return_tensors='pt')\n",
    "    encoded_bot_output = model.generate(encoded_user_input, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "    return tokenizer.decode(encoded_bot_output[:, encoded_user_input.shape[-1]:][0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8630257c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [21/Mar/2024 13:54:49] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2024 13:54:50] \"GET /static/style.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Mar/2024 13:54:50] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [21/Mar/2024 13:54:54] \"POST /get HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_to_profile.joblib loaded\n",
      "profile_to_index.joblib loaded\n",
      "Model Load Complete\n",
      "No module named 'pandas.core.indexes.numeric' a\n",
      "No module named 'pandas.core.indexes.numeric' a\n",
      "rating_data.joblib loaded\n",
      "Combined_Embedding.joblib loaded\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "global_data = {}\n",
    "Chat = memoizing_Chat()\n",
    "Google_drive_data_load()\n",
    "app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
